{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "Environment variables loaded:\n",
      "HF_HOME /pfss/mlde/workspaces/mlde_wsp_PI_Kersting/LLaVA-cake/Cyclist/hfcache\n",
      "HUGGINGFACE_HUB_CACHE /pfss/mlde/workspaces/mlde_wsp_PI_Kersting/LLaVA-cake/Cyclist/hfcache\n",
      "WANDB_PROJECT llava-changes\n",
      "TOKENIZERS_PARALLELISM true\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from utils.load_env_vars import load_env\n",
    "\n",
    "load_env()\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from data.dataloader import CyListSceneUnderstandingDataset, CyListVQADataset\n",
    "from judge.judge_utils import query_sglang_llama3, query_sglang_llama3_batched\n",
    "import json \n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load samples to check against the judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, can you judge this prediction for my visual question answering dataset? The question is about counting objects with certain properties and the answer is a numbers. \n",
      "\n",
      "Tell me if the model predicted the correct number. Give a score of 1 if the model predicted the groundtruth and 0 if the number is not the same as the groundtruth.\n",
      "\n",
      "\n",
      "return a json object with the following format:\n",
      "{{\n",
      "    \"prediction\": \"There is one cycling object.\",\n",
      "    \"groundtruth\": \"1\",\n",
      "    \"score\": 1\n",
      "    \"type\": \"TP\"\n",
      "}}\n",
      "\n",
      "Prediction:\n",
      "{}\n",
      "\n",
      "GT:\n",
      "{}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load txt file\n",
    "\n",
    "with open('/pfss/mlde/workspaces/mlde_wsp_Multimodal_on_42/CycliST/Cyclist/assets/prompts/vqa_prompt_counting.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    judge_prompt = ''.join(lines)\n",
    "    print(judge_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating /pfss/mlde/workspaces/mlde_wsp_Multimodal_on_42/CycliST/Cyclist/output/eval/unicycle_count_answer.csv\n",
      "PRED One object, the golden sphere, is changing its xy coordinates.\n",
      "ANSWER 1\n",
      "Hey, can you judge this prediction for my visual question answering dataset? The Answers can be given as a whole sentence or simple yes/no or attributes like 'color' or 'shape' or 'size' etc.\n",
      "\n",
      "Tell me if the have a true positive, false positive, true negative or false negative. \n",
      "A true positive is when the prediction is true and the ground truth is true, a false positive is when the prediction is true and the ground truth is false, a true negative is when the prediction is false and the ground truth is false and a false negative is when the prediction is false and the GT is true.\n",
      "Put this into the json as shown above. Use the following format for this: true positive, false positive, true negative, false negative.\n",
      "\n",
      "some examples are:\n",
      "the model says 'red' and the ground truth is 'red' -> TP\n",
      "the model says 'true' and the ground truth is 'true' -> TP\n",
      "the model says 'red' and the ground truth is 'blue' -> FP\n",
      "the model says 'true' and the ground truth is 'false' -> FP\n",
      "the model says 'no' and the ground truth is 'false' -> TN\n",
      "the model says 'false' and the ground truth is 'true' -> FN\n",
      "\n",
      "Then give a score of 1 if the prediction is correct, i.e. a TP or TN, and 0 if the prediction is incorrect, i.e. a FP or FN.\n",
      "For example, if the prediction is 'red' and the groundtruth is 'red', you should give a score of 1. If the prediction is 'red' and the groundtruth is 'blue', you should give a score of 0. An empty answer should get a score of 0.\n",
      "\n",
      "Treat 1, yes and true as the same and 0, no false as the same.\n",
      "\n",
      "\n",
      "return a json object with the following format:\n",
      "{{\n",
      "    \"prediction\": \"red\",\n",
      "    \"groundtruth\": \"red\",\n",
      "    \"score\": 1\n",
      "    \"type\": \"TP\"\n",
      "}}\n",
      "\n",
      "Prediction:\n",
      "{}\n",
      "\n",
      "GT:\n",
      "{}\n",
      "\n",
      "{'prediction': 'One object, the golden sphere, is changing its xy coordinates.', 'groundtruth': '1', 'score': 1, 'type': 'TP'}\n",
      "ERROR\n",
      "---------------------------------\n",
      "PRED There is one object, the small blue cone, that changes its position.\n",
      "ANSWER 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPRED\u001b[39m\u001b[38;5;124m\"\u001b[39m,pred)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mANSWER\u001b[39m\u001b[38;5;124m\"\u001b[39m,answer)\n\u001b[0;32m---> 28\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mquery_sglang_llama3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjudge_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjudge_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m json_response \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m(.|\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mr?\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mn)*}\u001b[39m\u001b[38;5;124m'\u001b[39m, response)\u001b[38;5;241m.\u001b[39mgroup()\n\u001b[1;32m     30\u001b[0m json_response \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(json_response)\n",
      "File \u001b[0;32m~/Cyclist/cyclist/eval/judge/judge_utils.py:37\u001b[0m, in \u001b[0;36mquery_sglang_llama3\u001b[0;34m(pred, gt, max_tokens, judge_prompt)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mquery_sglang_llama3\u001b[39m(pred, gt, max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m700\u001b[39m, judge_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 37\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdefault\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a helpful AI assistant helping me score the predictions of a model.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mjudge_prompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m700\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/envs/cycle_env/lib/python3.10/site-packages/openai/_utils/_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/cycle_env/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py:925\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    922\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    923\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    924\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/cycle_env/lib/python3.10/site-packages/openai/_base_client.py:1239\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1226\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1227\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1235\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1236\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1237\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1238\u001b[0m     )\n\u001b[0;32m-> 1239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/envs/cycle_env/lib/python3.10/site-packages/openai/_base_client.py:969\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    967\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 969\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    975\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/envs/cycle_env/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/envs/cycle_env/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/envs/cycle_env/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/envs/cycle_env/lib/python3.10/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/envs/cycle_env/lib/python3.10/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m~/envs/cycle_env/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/envs/cycle_env/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/envs/cycle_env/lib/python3.10/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/cycle_env/lib/python3.10/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/envs/cycle_env/lib/python3.10/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/envs/cycle_env/lib/python3.10/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/cycle_env/lib/python3.10/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/envs/cycle_env/lib/python3.10/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load csv file with\n",
    "\n",
    "csv_paths =[ \"/pfss/mlde/workspaces/mlde_wsp_Multimodal_on_42/CycliST/Cyclist/output/eval/unicycle_count_answer.csv\"]\n",
    "\n",
    "for csv_path in csv_paths:\n",
    "    print(\"Evaluating\", csv_path)\n",
    "    # load csv\n",
    "    df = pd.read_csv(csv_path, sep=\";\", names=['query', 'answer','pred'])\n",
    "    #display(df.head())\n",
    "\n",
    "    types = {\"FP\": 0, \"TP\": 0, \"FN\": 0, \"TN\": 0}\n",
    "    score = 0\n",
    "    evaluated = 0\n",
    "\n",
    "\n",
    "    for idx, row in enumerate(df.iterrows()):\n",
    "        if idx > 4:\n",
    "            break\n",
    "        # question = row[1]\n",
    "        pred = row[1][1]\n",
    "        answer = row[1][2]\n",
    "        print(\"PRED\",pred)\n",
    "        print(\"ANSWER\",answer)\n",
    "\n",
    "        \n",
    "        response = query_sglang_llama3(pred, answer, judge_prompt=judge_prompt)\n",
    "        json_response = re.search(r'{(.|\\r?\\n)*}', response).group()\n",
    "        json_response = json.loads(json_response)\n",
    "        print(json_response)\n",
    "        if json_response['prediction'] == \"false\" and json_response['groundtruth'] == \"false\":\n",
    "            types[\"TN\"] += 1\n",
    "        elif json_response['prediction'] == \"true\" and json_response['groundtruth'] == \"true\":\n",
    "            types[\"TP\"] += 1\n",
    "        elif json_response['prediction'] == \"true\" and json_response['groundtruth'] == \"false\":\n",
    "            types[\"FP\"] += 1\n",
    "        elif json_response['prediction'] == \"false\" and json_response['groundtruth'] == \"true\":\n",
    "            types[\"FN\"] += 1\n",
    "        else:\n",
    "            print(\"ERROR\")\n",
    "        #types[json_response['type']] += 1\n",
    "        #if str(json_response['score']) == \"1\":\n",
    "        #    score += 1\n",
    "        evaluated += 1\n",
    "        print(\"---------------------------------\")\n",
    "\n",
    "    print(\"Accuracy\", score/evaluated)\n",
    "    print(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FP': 0, 'TP': 0, 'FN': 2, 'TN': 3}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# judge one sample at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating /pfss/mlde/workspaces/mlde_wsp_PI_Kersting/LLaVA-cake/Cyclist/data/answers/llava_ov_unicycle_fps_8/enlarge_low_answers.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/824 [00:00<?, ?it/s]/var/tmp/ipykernel_74410/772867585.py:26: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  pred = row[1][1]\n",
      "/var/tmp/ipykernel_74410/772867585.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  answer = row[1][2]\n",
      "  4%|▍         | 31/824 [02:25<1:02:01,  4.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.4838709677419355\n",
      "{'FP': 3, 'TP': 15, 'FN': 13, 'TN': 0}\n",
      "Evaluating /pfss/mlde/workspaces/mlde_wsp_PI_Kersting/LLaVA-cake/Cyclist/data/answers/llava_ov_unicycle_fps_8/linear_low_answers.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/961 [00:00<?, ?it/s]/var/tmp/ipykernel_74410/772867585.py:26: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  pred = row[1][1]\n",
      "/var/tmp/ipykernel_74410/772867585.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  answer = row[1][2]\n",
      "  3%|▎         | 31/961 [02:32<1:16:21,  4.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8064516129032258\n",
      "{'FP': 2, 'TP': 25, 'FN': 4, 'TN': 0}\n",
      "Evaluating /pfss/mlde/workspaces/mlde_wsp_PI_Kersting/LLaVA-cake/Cyclist/data/answers/llava_ov_unicycle_fps_8/orbit_low_answers.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1114 [00:00<?, ?it/s]/var/tmp/ipykernel_74410/772867585.py:26: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  pred = row[1][1]\n",
      "/var/tmp/ipykernel_74410/772867585.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  answer = row[1][2]\n",
      "  3%|▎         | 31/1114 [02:27<1:25:52,  4.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.5806451612903226\n",
      "{'FP': 1, 'TP': 18, 'FN': 12, 'TN': 0}\n",
      "Evaluating /pfss/mlde/workspaces/mlde_wsp_PI_Kersting/LLaVA-cake/Cyclist/data/answers/llava_ov_unicycle_fps_8/recolor_low_answers.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1063 [00:00<?, ?it/s]/var/tmp/ipykernel_74410/772867585.py:26: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  pred = row[1][1]\n",
      "/var/tmp/ipykernel_74410/772867585.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  answer = row[1][2]\n",
      "  3%|▎         | 31/1063 [02:05<1:09:26,  4.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6451612903225806\n",
      "{'FP': 2, 'TP': 20, 'FN': 9, 'TN': 0}\n",
      "Evaluating /pfss/mlde/workspaces/mlde_wsp_PI_Kersting/LLaVA-cake/Cyclist/data/answers/llava_ov_unicycle_fps_8/rotation_low_answers.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/975 [00:00<?, ?it/s]/var/tmp/ipykernel_74410/772867585.py:26: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  pred = row[1][1]\n",
      "/var/tmp/ipykernel_74410/772867585.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  answer = row[1][2]\n",
      "  3%|▎         | 31/975 [02:21<1:11:40,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7419354838709677\n",
      "{'FP': 2, 'TP': 23, 'FN': 6, 'TN': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load csv file with\n",
    "\n",
    "csv_paths =[ \"/pfss/mlde/workspaces/mlde_wsp_PI_Kersting/LLaVA-cake/Cyclist/data/answers/llava_ov_unicycle_fps_8/enlarge_low_answers.csv\",\n",
    "            \"/pfss/mlde/workspaces/mlde_wsp_PI_Kersting/LLaVA-cake/Cyclist/data/answers/llava_ov_unicycle_fps_8/linear_low_answers.csv\",\n",
    "            \"/pfss/mlde/workspaces/mlde_wsp_PI_Kersting/LLaVA-cake/Cyclist/data/answers/llava_ov_unicycle_fps_8/orbit_low_answers.csv\",\n",
    "            \"/pfss/mlde/workspaces/mlde_wsp_PI_Kersting/LLaVA-cake/Cyclist/data/answers/llava_ov_unicycle_fps_8/recolor_low_answers.csv\",\n",
    "            \"/pfss/mlde/workspaces/mlde_wsp_PI_Kersting/LLaVA-cake/Cyclist/data/answers/llava_ov_unicycle_fps_8/rotation_low_answers.csv\"]\n",
    "\n",
    "for csv_path in csv_paths:\n",
    "    print(\"Evaluating\", csv_path)\n",
    "    # load csv\n",
    "    df = pd.read_csv(csv_path, sep=\";\", names=['query', 'answer','pred'])\n",
    "    #display(df.head())\n",
    "\n",
    "    types = {\"FP\": 0, \"TP\": 0, \"FN\": 0, \"TN\": 0}\n",
    "    score = 0\n",
    "    evaluated = 0\n",
    "\n",
    "\n",
    "    for idx, row in enumerate(tqdm(df.iterrows(), total=len(df))):\n",
    "        if idx > 50:\n",
    "            break\n",
    "        # question = row[1]\n",
    "        pred = row[1][1]\n",
    "        answer = row[1][2]\n",
    "\n",
    "        #print(pred, answer)\n",
    "        \n",
    "        response = query_sglang_llama3(pred, answer)\n",
    "        json_response = re.search(r'{(.|\\r?\\n)*}', response).group()\n",
    "        json_response = json.loads(json_response)\n",
    "        # print(json_response['score'], json_response['type'])\n",
    "        types[json_response['type']] += 1\n",
    "        if str(json_response['score']) == \"1\":\n",
    "            score += 1\n",
    "        evaluated += 1\n",
    "\n",
    "    print(\"Accuracy\", score/evaluated)\n",
    "    print(types)\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# batched processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "client = openai.Client(\n",
    "    base_url=\"http://127.0.0.1:30000/v1\", api_key=\"EMPTY\")\n",
    "\n",
    "\n",
    "\n",
    "judge_prompt= \"\"\"\n",
    "Hey, can you judge this prediction for my visual question answering dataset? The Answers can be given as a whole sentence or simple yes/no or attributes like 'color' or 'shape' or 'size' etc.\n",
    "\n",
    "all forms of false like 'no', 'false', '0' should be mapped into false\n",
    "all forms of true like 'yes', 'true', '1' are the same and should be mapped into false\n",
    "\n",
    "Can you  map me the prediction and answer into the following format:\n",
    "{{\n",
    "    \"prediction\": \"<true, false>\",\n",
    "    \"groundtruth\": \"<true, false>\"\n",
    "}}\n",
    "\n",
    "Prediction:\n",
    "{}\n",
    "\n",
    "GT:\n",
    "{}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating /pfss/mlde/workspaces/mlde_wsp_PI_Kersting/LLaVA-cake/Cyclist/data/answers/llava_ov_unicycle_fps_8/enlarge_low_answers.csv\n",
      "Batch job created with ID: batch_7d99c823-5584-4a65-b2f6-bfeb10f15912\n",
      "Batch job status: validating...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job completed successfully!\n",
      "Request counts: BatchRequestCounts(completed=824, failed=0, total=824)\n",
      "loading data from file backend_result_file-a8fbf75b-62ec-4e8b-b17b-524ca67756a8\n",
      "Cleaning up files...\n",
      "Evaluating /pfss/mlde/workspaces/mlde_wsp_PI_Kersting/LLaVA-cake/Cyclist/data/answers/llava_ov_unicycle_fps_8/linear_low_answers.csv\n",
      "Batch job created with ID: batch_6a6bc103-b8ed-4499-aa02-c6573df201d3\n",
      "Batch job status: validating...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job completed successfully!\n",
      "Request counts: BatchRequestCounts(completed=961, failed=0, total=961)\n",
      "loading data from file backend_result_file-cea9e89c-5eda-4262-8606-dfbdc5be6534\n",
      "Cleaning up files...\n",
      "Evaluating /pfss/mlde/workspaces/mlde_wsp_PI_Kersting/LLaVA-cake/Cyclist/data/answers/llava_ov_unicycle_fps_8/orbit_low_answers.csv\n",
      "Batch job created with ID: batch_ea937cdf-edf7-4149-8036-f4a02ad0e185\n",
      "Batch job status: validating...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job completed successfully!\n",
      "Request counts: BatchRequestCounts(completed=1114, failed=0, total=1114)\n",
      "loading data from file backend_result_file-28a142bd-e01d-4569-8e6a-23a625358b61\n",
      "Cleaning up files...\n",
      "Evaluating /pfss/mlde/workspaces/mlde_wsp_PI_Kersting/LLaVA-cake/Cyclist/data/answers/llava_ov_unicycle_fps_8/recolor_low_answers.csv\n",
      "Batch job created with ID: batch_f14f9a7d-765c-454e-9f72-e92acbf627fe\n",
      "Batch job status: validating...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job completed successfully!\n",
      "Request counts: BatchRequestCounts(completed=1063, failed=0, total=1063)\n",
      "loading data from file backend_result_file-da2ae868-7202-4ed9-aa95-0dd014786c18\n",
      "Cleaning up files...\n",
      "Evaluating /pfss/mlde/workspaces/mlde_wsp_PI_Kersting/LLaVA-cake/Cyclist/data/answers/llava_ov_unicycle_fps_8/rotation_low_answers.csv\n",
      "Batch job created with ID: batch_998ad426-cf39-4418-938d-770d1745297c\n",
      "Batch job status: validating...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job status: in_progress...trying again in 5 seconds...\n",
      "Batch job completed successfully!\n",
      "Request counts: BatchRequestCounts(completed=975, failed=0, total=975)\n",
      "loading data from file backend_result_file-3282f235-c3bf-4fc4-9583-f6b827fb4c6c\n",
      "Cleaning up files...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "# load csv file with\n",
    "base_path = \"/pfss/mlde/workspaces/mlde_wsp_PI_Kersting/LLaVA-cake/Cyclist/data/answers/\"\n",
    "cycles = [\"enlarge\", \"linear\", \"orbit\", \"recolor\", \"rotation\"]\n",
    "clutter = [\"low\"]\n",
    "\n",
    "\n",
    "last_idx =0\n",
    "results_all_cycles = []\n",
    "for cyc in cycles:\n",
    "    for clut in clutter:\n",
    "        csv_path = base_path + f\"llava_ov_unicycle_fps_8/{cyc}_{clut}_answers.csv\"\n",
    "        client = OpenAI(base_url=f\"http://127.0.0.1:30000/v1\", api_key=\"None\")\n",
    "\n",
    "\n",
    "        print(\"Evaluating\", csv_path)\n",
    "        # load csv\n",
    "        df = pd.read_csv(csv_path, sep=\";\", names=['query', 'answer','pred'])\n",
    "        #display(df.head())\n",
    "\n",
    "        types = {\"FP\": 0, \"TP\": 0, \"FN\": 0, \"TN\": 0}\n",
    "        score = 0\n",
    "        evaluated = 0\n",
    "\n",
    "        \n",
    "        #create batch json to send to llm\n",
    "        batch_size = len(df)\n",
    "        for chunk in np.array_split(df, int(len(df)/batch_size)):\n",
    "\n",
    "            pred = chunk['pred']\n",
    "            answer = chunk['answer']\n",
    "            \n",
    "            requests = []\n",
    "            for idx, (p, a) in enumerate(zip(pred, answer)):\n",
    "                requests.append(\n",
    "                    {\n",
    "                        \"custom_id\": \"request-{}\".format(idx+ last_idx),\n",
    "                        \"method\": \"POST\",\n",
    "                        \"url\": \"/chat/completions\",\n",
    "                        \"body\": {\n",
    "                            \"model\": \"meta-llama/Meta-Llama-3-70B-Instruct\",\n",
    "                            \"messages\": [\n",
    "                                {\"role\": \"system\", \"content\": \"You are a helpful AI assistant helping me score the predictions of a model.\"},\n",
    "                                {\"role\": \"user\",\n",
    "                                \"content\": judge_prompt.format(p, a)},\n",
    "                            ],\n",
    "                            \"max_tokens\": 200,\n",
    "                        },\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            input_file_path = \"batch_requests_{}_{}.jsonl\".format(cyc, clut)\n",
    "\n",
    "            # Write the requests to a file\n",
    "            with open(input_file_path, \"w\") as f:\n",
    "                for req in requests:\n",
    "                    f.write(json.dumps(req) + \"\\n\")\n",
    "                    \n",
    "            # Send the file to OpenAI\n",
    "            with open(input_file_path, \"rb\") as f:\n",
    "                file_response = client.files.create(file=f, purpose=\"batch\")\n",
    "                \n",
    "            batch_response = client.batches.create(\n",
    "            input_file_id=file_response.id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\",\n",
    "            )\n",
    "\n",
    "            print(f\"Batch job created with ID: {batch_response.id}\")\n",
    "            \n",
    "            # check if batch was completed\n",
    "            while batch_response.status not in [\"completed\", \"failed\", \"cancelled\"]:\n",
    "                time.sleep(3)\n",
    "                print(f\"Batch job status: {batch_response.status}...trying again in 5 seconds...\")\n",
    "                batch_response = client.batches.retrieve(batch_response.id)\n",
    "\n",
    "            # if batch was completed, get the results\n",
    "            if batch_response.status == \"completed\":\n",
    "                print(\"Batch job completed successfully!\")\n",
    "                print(f\"Request counts: {batch_response.request_counts}\")\n",
    "\n",
    "                print(\"loading data from file\", batch_response.output_file_id)\n",
    "                result_file_id = batch_response.output_file_id\n",
    "                file_response = client.files.content(result_file_id)\n",
    "                result_content = file_response.read().decode(\"utf-8\")\n",
    "\n",
    "                results = [\n",
    "                    json.loads(line) for line in result_content.split(\"\\n\") if line.strip() != \"\"\n",
    "                ]\n",
    "                results_all_cycles.append(results)\n",
    "\n",
    "                # for result in results:\n",
    "                #     print(f\"Request {result['custom_id']}:\")\n",
    "                #     # print(f\"Response: {result['response']}\")\n",
    "                #     print(result['response']['body']['choices']['message']['content'])\n",
    "\n",
    "                print(\"Cleaning up files...\")\n",
    "                # Only delete the result file ID since file_response is just content\n",
    "                client.files.delete(result_file_id)\n",
    "            else:\n",
    "                print(f\"Batch job failed with status: {batch_response.status}\")\n",
    "                if hasattr(batch_response, \"errors\"):\n",
    "                    print(f\"Errors: {batch_response.errors}\")\n",
    "            last_idx += idx\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "Cycle enlarge\n",
      "{'FP': 192, 'TP': 214, 'FN': 33, 'TN': 380}\n",
      "Accuracy 0.7252747252747253\n",
      "Precision 0.5270935960591133\n",
      "Recall 0.8663967611336032\n",
      "F1 0.6554364471669218\n",
      "--------\n",
      "Cycle linear\n",
      "{'FP': 205, 'TP': 234, 'FN': 52, 'TN': 419}\n",
      "Accuracy 0.7175824175824176\n",
      "Precision 0.5330296127562643\n",
      "Recall 0.8181818181818182\n",
      "F1 0.6455172413793104\n",
      "--------\n",
      "Cycle orbit\n",
      "{'FP': 163, 'TP': 405, 'FN': 54, 'TN': 428}\n",
      "Accuracy 0.7933333333333333\n",
      "Precision 0.7130281690140845\n",
      "Recall 0.8823529411764706\n",
      "F1 0.7887049659201557\n",
      "--------\n",
      "Cycle recolor\n",
      "{'FP': 184, 'TP': 374, 'FN': 67, 'TN': 427}\n",
      "Accuracy 0.7614068441064639\n",
      "Precision 0.6702508960573477\n",
      "Recall 0.8480725623582767\n",
      "F1 0.7487487487487489\n",
      "--------\n",
      "Cycle rotation\n",
      "{'FP': 194, 'TP': 289, 'FN': 29, 'TN': 459}\n",
      "Accuracy 0.7703398558187435\n",
      "Precision 0.598343685300207\n",
      "Recall 0.9088050314465409\n",
      "F1 0.7215980024968789\n"
     ]
    }
   ],
   "source": [
    "for results, cycle in zip(results_all_cycles, cycles):\n",
    "    score = 0\n",
    "    evaluated = 0\n",
    "    types = {\"FP\": 0, \"TP\": 0, \"FN\": 0, \"TN\": 0}\n",
    "    for result in results:\n",
    "        # print(f\"Request {result['custom_id']}:\")\n",
    "        # print(f\"Response: {result['response']}\")\n",
    "        response = result['response']['body']['choices']['message']['content']\n",
    "\n",
    "        try:\n",
    "            #parse json from response\n",
    "            # json_response = re.search(r'{(.|\\r?\\n)*}', response).group()\n",
    "            # json_response = json.loads(json_response)\n",
    "            # # print(json_response['score'], json_response['type'])\n",
    "            # types[json_response['type']] += 1\n",
    "            # if str(json_response['score']) == \"1\":\n",
    "            #     score += 1\n",
    "            # evaluated += 1\n",
    "            \n",
    "            \n",
    "            json_response = re.search(r'{(.|\\r?\\n)*}', response).group()\n",
    "            json_response = json.loads(json_response)\n",
    "            if json_response['prediction'] == \"false\" and json_response['groundtruth'] == \"false\":\n",
    "                types[\"TN\"] += 1\n",
    "                score += 1\n",
    "            elif json_response['prediction'] == \"true\" and json_response['groundtruth'] == \"true\":\n",
    "                types[\"TP\"] += 1\n",
    "                score += 1\n",
    "            elif json_response['prediction'] == \"true\" and json_response['groundtruth'] == \"false\":\n",
    "                types[\"FP\"] += 1\n",
    "            elif json_response['prediction'] == \"false\" and json_response['groundtruth'] == \"true\":\n",
    "                types[\"FN\"] += 1\n",
    "            else:\n",
    "                continue\n",
    "                #print(\"ERROR\")\n",
    "            #types[json_response['type']] += 1\n",
    "            #if str(json_response['score']) == \"1\":\n",
    "            #    score += 1\n",
    "            evaluated += 1\n",
    "            # print(\"---------------------------------\")\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "    print(\"--------\")\n",
    "    print(\"Cycle\", cycle)\n",
    "    print(types)\n",
    "    precision = types[\"TP\"] / (types[\"TP\"] + types[\"FP\"])\n",
    "    recall = types[\"TP\"] / (types[\"TP\"] + types[\"FN\"])\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    print(\"Accuracy\", score/evaluated)\n",
    "    print(\"Precision\", precision)\n",
    "    print(\"Recall\", recall)\n",
    "    print(\"F1\", f1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "824"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_all_cycles[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
